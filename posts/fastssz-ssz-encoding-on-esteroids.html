<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><script defer="" data-domain="ferranbt.com" src="https://plausible.io/js/plausible.js"></script><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/c46f57c4716cbe03.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/c46f57c4716cbe03.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-5429a50ba5373c56.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-930135e47dff83e9.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-0b15ebdcc6cba1cf.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-171cb00964061ffe.js" defer="" crossorigin=""></script><script src="/_next/static/BvrQde1H6ouQhX5j2uX21/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/BvrQde1H6ouQhX5j2uX21/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"><div class="container"><header class="pt-10"><div class="mx-auto flex justify-between items-center"><nav><ul class="flex space-x-4"><li><a class="hover:text-gray-400 underline" href="/">Home</a></li><li><a class="hover:text-gray-400 underline" href="/about">About</a></li><li><a class="hover:text-gray-400 underline" href="https://twitter.com/ferranbt">Twitter</a><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-4 w-4 mb-1 inline ml-1"><path fill-rule="evenodd" d="M15.75 2.25H21a.75.75 0 0 1 .75.75v5.25a.75.75 0 0 1-1.5 0V4.81L8.03 17.03a.75.75 0 0 1-1.06-1.06L19.19 3.75h-3.44a.75.75 0 0 1 0-1.5Zm-10.5 4.5a1.5 1.5 0 0 0-1.5 1.5v10.5a1.5 1.5 0 0 0 1.5 1.5h10.5a1.5 1.5 0 0 0 1.5-1.5V10.5a.75.75 0 0 1 1.5 0v8.25a3 3 0 0 1-3 3H5.25a3 3 0 0 1-3-3V8.25a3 3 0 0 1 3-3h8.25a.75.75 0 0 1 0 1.5H5.25Z" clip-rule="evenodd"></path></svg></li><li><a class="hover:text-gray-400 underline" href="https://github.com/ferranbt">Github</a><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-4 w-4 mb-1 inline ml-1"><path fill-rule="evenodd" d="M15.75 2.25H21a.75.75 0 0 1 .75.75v5.25a.75.75 0 0 1-1.5 0V4.81L8.03 17.03a.75.75 0 0 1-1.06-1.06L19.19 3.75h-3.44a.75.75 0 0 1 0-1.5Zm-10.5 4.5a1.5 1.5 0 0 0-1.5 1.5v10.5a1.5 1.5 0 0 0 1.5 1.5h10.5a1.5 1.5 0 0 0 1.5-1.5V10.5a.75.75 0 0 1 1.5 0v8.25a3 3 0 0 1-3 3H5.25a3 3 0 0 1-3-3V8.25a3 3 0 0 1 3-3h8.25a.75.75 0 0 1 0 1.5H5.25Z" clip-rule="evenodd"></path></svg></li></ul></nav></div></header><main class="flex min-h-screen flex-col items-center justify-between py-14"><div class="z-10 w-full items-center justify-between font-mono text-sm"><div class="mb-8"><h1 class="text-2xl font-bold">FastSSZ: SZZ encoding on esteroids</h1></div><main class="prose max-w-none"><p>A few years back, the Prysmatic Labs team, developers of the Ethereum Beacon chain <a href="https://github.com/prysmaticlabs/prysm">Prysm</a> <a href="https://github.com/prysmaticlabs/prysm/issues/4738">opened a bounty</a> to replace their implementation (<a href="https://github.com/prysmaticlabs/go-ssz">go-ssz</a>) of the SSZ encoding protocol.</p>
<p>Having worked with <a href="https://github.com/umbracle/fastrlp">encoding libraries</a> and <a href="https://github.com/umbracle/minimal">high-performance</a> systems in the blockchain space, I had some ideas I wanted to try out.</p>
<p>After some successful experiments and a little bit of coding, this was the result:</p>
<pre class="language-go"><code class="language-go">BenchmarkMarshalGoSSZ<span class="token operator">-</span><span class="token number">4</span>       	  <span class="token number">753160</span> ns<span class="token operator">/</span>op	  <span class="token number">115112</span> B<span class="token operator">/</span>op	    <span class="token number">8780</span> allocs<span class="token operator">/</span>op
BenchmarkUnMarshalGoSSZ<span class="token operator">-</span><span class="token number">4</span>     	  <span class="token number">1395097</span> ns<span class="token operator">/</span>op	  <span class="token number">144608</span> B<span class="token operator">/</span>op	    <span class="token number">8890</span> allocs<span class="token operator">/</span>op
BenchmarkMarshal_Fast<span class="token operator">-</span><span class="token number">8</span>           <span class="token number">4088</span> ns<span class="token operator">/</span>op	    <span class="token number">8192</span> B<span class="token operator">/</span>op	       <span class="token number">1</span> allocs<span class="token operator">/</span>op
BenchmarkMarshal_SuperFast<span class="token operator">-</span><span class="token number">8</span>      <span class="token number">1354</span> ns<span class="token operator">/</span>op	       <span class="token number">0</span> B<span class="token operator">/</span>op	       <span class="token number">0</span> allocs<span class="token operator">/</span>op
BenchmarkUnMarshal_Fast<span class="token operator">-</span><span class="token number">8</span>         <span class="token number">17614</span> ns<span class="token operator">/</span>op	   <span class="token number">11900</span> B<span class="token operator">/</span>op	     <span class="token number">210</span> allocs<span class="token operator">/</span>op
BenchmarkHashTreeRoot_Fast<span class="token operator">-</span><span class="token number">8</span>      <span class="token number">45932</span> ns<span class="token operator">/</span>op	       <span class="token number">0</span> B<span class="token operator">/</span>op	       <span class="token number">0</span> allocs<span class="token operator">/</span>op
</code></pre>
<p>For those of you who are not used to Go benchmarks, this is an x500 improvement for message encoding over the original (go-ssz) implementation.</p>
<p>In this blog, I want to give a walkthrough into optimizations behind the library and some of the design decisions. I will focus mostly on encoding and hashing (and a bit less on decoding) since that is where most of the high-performance strategies are located.</p>
<h3>What is SSZ?</h3>
<p>Simple Serialize (SSZ) is a binary data serialization format used in the Ethereum Beacon chain. It replaces the RLP serialization used in the execution clients. Unlike RLP which only specifies the encoding format, SSZ also defines how the objects are Merkleize efficiently.</p>
<p>SSZ is deterministic and not self-describing, to decode a blob of binary data, the message schema must be known in advance. This differs from Protobuf which encodes in the message itself a description of the format.</p>
<p>Encoding in SSZ is similar in nature to the <a href="https://docs.soliditylang.org/en/v0.8.19/abi-spec.html">ABI format</a> to interact with smart contracts. The result byte stream is divided into two parts: fixed and heap areas. Basic and static values (i.e. integer, bool, fixed size bytes) are appended to the fixed area while dynamic types are written to the heap area recursively following the same rules. An offset is written in the fixed area to the point in the heap where the value starts.</p>
<p>SSZ objects can also be transformed into a <a href="https://www.notion.so/Clickhouse-event-tracker-4e8b68a29f62412a9d44d50ba81216c9?pvs=21">Merkle-tree</a> representation. The values of the object are recursively split into chunks of 32 bytes and hashed into a Merkle-tree. Additional empty leaves might be included so that the total number of leaves is a power of 2 and a single hash-tree-root is produced.</p>
<h3>Limitations in Golang</h3>
<p>Even though Go does support generic types now, it is still not possible to create a generic data serialization library without the use of the reflect package, a meta-programming tool in Go to determine the shape of the objects at runtime.</p>
<p>A simple encoding library with reflection might look like this:</p>
<pre class="language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">encode</span><span class="token punctuation">(</span>i <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span> <span class="token punctuation">{</span>
  res <span class="token operator">:=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">{</span><span class="token punctuation">}</span>
  <span class="token keyword">switch</span> reflect<span class="token punctuation">.</span><span class="token function">TypeOf</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Kind</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">case</span> reflect<span class="token punctuation">.</span>Int64<span class="token punctuation">:</span>
      <span class="token comment">// encode int 64</span>
		<span class="token keyword">case</span> reflect<span class="token punctuation">.</span>String<span class="token punctuation">:</span>
			<span class="token comment">// encode string</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>However, it comes with a cost: it is hard to debug, error-prone, and inefficient.</p>
<h3>An iterative approach to encoding</h3>
<p>Before <code>fastssz</code>, I built <code>[fastrlp](https://github.com/umbracle/fastrlp)</code>, a Go library to encode the RLP format of the execution clients. <code>fastrlp</code> is based on <code>[fastjson](https://github.com/valyala/fastjson)</code> and follows the same structures and optimizations.</p>
<p><code>fastrlp</code> is not an encoding library, but a set of low-level primitives and utilities to encode/decode objects in RLP. The library is small and low-maintenance and if used correctly, it does not allocate any memory.</p>
<p>This is an example of how to use <code>fastrlp</code> to encode a simple object with two fields:</p>
<pre class="language-go"><code class="language-go"><span class="token keyword">type</span> Obj <span class="token keyword">struct</span> <span class="token punctuation">{</span>
  A <span class="token builtin">uint64</span>
  B <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span>
<span class="token punctuation">}</span>

<span class="token keyword">func</span> <span class="token function">Encode</span><span class="token punctuation">(</span>o <span class="token operator">*</span>Obj<span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span> <span class="token punctuation">{</span>
  a <span class="token operator">:=</span> <span class="token operator">&amp;</span>fastrlp<span class="token punctuation">.</span>Arena<span class="token punctuation">{</span><span class="token punctuation">}</span>
  v <span class="token operator">:=</span> a<span class="token punctuation">.</span><span class="token function">NewArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  v<span class="token punctuation">.</span><span class="token function">Set</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span><span class="token function">NewUint</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>A<span class="token punctuation">)</span><span class="token punctuation">)</span>
  v<span class="token punctuation">.</span><span class="token function">Set</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span><span class="token function">NewBytes</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>B<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> v<span class="token punctuation">.</span><span class="token function">Marshal</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre>
<p>However, it becomes cumbersome and error-prone to manually write down (and review) the encoding/decoding for each object (<a href="https://github.com/0xPolygon/polygon-edge/blob/develop/types/rlp_unmarshal.go">here</a>, <a href="https://github.com/umbracle/ethgo/blob/main/structs_marshal_rlp.go">here</a>).</p>
<p>This is less of a problem for RLP since only a handful of small objects require encoding. But, it is not an option for the Beacon chain which has <a href="https://github.com/ferranbt/fastssz/blob/main/spectests/structs.go">dozens of objects</a> that require SSZ encoding. Thus, I decided to try out code generation to scale the process.</p>
<h3>Code generation is far from perfect</h3>
<p>Most often than not, code generation is used to generate language-specific SDK based on some simple and generic configuration format (i.e. Protobuf, OpenAPI, Kubernetes CRDs, etc…).</p>
<p>In this case, though Prism does define the Beacon chain objects as <a href="https://www.notion.so/FastSSZ-SSZ-encoding-on-steroids-e7a2b6eca63b4436936019833a36f8fe?pvs=21">Protobuf</a>, I decided to work with the Go types instead, not to require any extra bindings to make it work. This decision turned out to have mixed results.</p>
<p>On one side, it was adopted by other projects (<a href="https://github.com/Snowfork/snowbridge">here</a>, <a href="https://github.com/flashbots/mev-boost-relay">here</a>) without requiring Protobuf. On the other, when you take as input any arbitrary Go code (and not a constrained schema) you end up facing many Go-specific syntaxes that need support (or at the very least, design discussions), to name a few: import external packages, import with alias names, multiple-target compilation, type alias, etc…</p>
<p>A positive aspect of SSZ is that currently is only used for the Ethereum <a href="https://www.notion.so/FastSSZ-SSZ-encoding-on-steroids-e7a2b6eca63b4436936019833a36f8fe?pvs=21">Beacon chain types</a> which are only updated a few times a year. There are not usually new field types that need to be implemented (zero in the last fork).</p>
<p>Thus, on this aspect, once the code has been generated as it is optimal (more on this in the next section) maintenance is minimal.</p>
<h3>Divide and conquer</h3>
<p>Something I found useful while I iterated from <code>fastrlp</code> to <code>fastssz</code> was to split the system into two layers. On one side the set of high-performance low-level primitives and on the other the code generation (aka <code>sszgen</code>).</p>
<p>Some of the benefits are:</p>
<ul>
<li>You can optimize and benchmark the encoding outside the generated code.</li>
<li>The generated code gets more succinct and easier to read and debug (<a href="https://github.com/ferranbt/fastssz/blob/main/spectests/structs_encoding.go">example</a>).</li>
<li>There might be simple scenarios where you want to use the primitives without generating code (<a href="https://github.com/umbracle/go-eth-consensus/blob/main/spec/rewards.go#L21">example</a>).</li>
<li>You can update the library with the primitives without updating the generated code.</li>
</ul>
<h3>Here be dragons! Zero-memory allocation.</h3>
<p>Once you remove reflection from the picture, the biggest sinkhole of memory and CPU cycles is going to be memory allocation. Thus, it was my intention to make <code>fastssz</code> a zero-allocation library from the get-go.</p>
<p>First, let&#x27;s dive in into encoding which is simpler to speed up in SSZ.</p>
<p>Most of the encoding libraries in the literature look like this:</p>
<pre class="language-go"><code class="language-go"><span class="token keyword">type</span> Obj <span class="token keyword">struct</span> <span class="token punctuation">{</span>
  Data <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span>
<span class="token punctuation">}</span>

<span class="token keyword">func</span> <span class="token function">Encode</span><span class="token punctuation">(</span>obj <span class="token operator">*</span>Obj<span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span> <span class="token punctuation">{</span>
  buf <span class="token operator">:=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">)</span>
  buf <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> obj<span class="token punctuation">.</span>Data<span class="token operator">...</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> buf
<span class="token punctuation">}</span>
</code></pre>
<p>In this function, byte allocation for the result happens inside the library. Depending on the object, this allocation might vary a lot in size and might have to be rescaled multiple times. Besides, when executed many times, it creates extra pressure on the gc collector both to allocate the bytes and to track its lifecycle.</p>
<p>It should be preferable to shift left the allocation and use a destination buffer like this:</p>
<pre class="language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">Encode</span><span class="token punctuation">(</span>dst <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">,</span> obj <span class="token operator">*</span>Obj<span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span> <span class="token punctuation">{</span>
  dst <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>dst<span class="token punctuation">,</span> obj<span class="token punctuation">.</span>Data<span class="token operator">...</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> dst
<span class="token punctuation">}</span>
</code></pre>
<p>This is similar to the allocation pattern used in the Zig language.</p>
<p>Then, we remove both the allocation and give more options to the user on how to call this function:</p>
<pre class="language-go"><code class="language-go">buf <span class="token operator">:=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">{</span><span class="token punctuation">}</span>
obj <span class="token operator">:=</span> <span class="token operator">&amp;</span>Obj<span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token comment">// 1. Encoding gets written to the buffer.</span>
buf <span class="token operator">=</span> <span class="token function">Encode</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> obj<span class="token punctuation">)</span>

<span class="token comment">// 2. The buffer is reused from the beginning and overwritten with</span>
<span class="token comment">// new data.</span>
buf <span class="token operator">=</span> <span class="token function">Encode</span><span class="token punctuation">(</span>buf<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> obj<span class="token punctuation">)</span>

<span class="token comment">// 3. A new buffer is created. Original buffer is garbage collected.</span>
buf <span class="token operator">=</span> <span class="token function">Encode</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">,</span> obj<span class="token punctuation">)</span>
</code></pre>
<p>Following this pattern, encoding with SSZ is a matter of writing into the destination buffer each field of the object in the correct order (<a href="https://github.com/ferranbt/fastssz/blob/main/spectests/structs_encoding.go#L128">example</a>).</p>
<p>Let’s look at hashing now. In insight, it follows the same principles as encoding except for a couple of differences:</p>
<ul>
<li>The result is not a byte stream but a root hash (32 bytes). But, it requires converting the fields into bytes and allocating those intermediate representations somewhere.</li>
<li>While the logic in encoding only involves appending bytes into a buffer, for hashing the logic is more complex and requires merkle tree hashing (<a href="https://github.com/ferranbt/fastssz/blob/v0.1.3/hasher.go#L343">example</a>).</li>
</ul>
<p>The pattern to optimize these operations is similar to encoding, but instead of using <code>[]byte</code> as the allocation object, we create a <code>Hasher</code> object that encapsulates both the complex hashing logic and the allocation of memory. When doing the hashing of an object, a <code>Hasher</code> object has to be passed as well to the function.</p>
<pre class="language-go"><code class="language-go"><span class="token keyword">type</span> Hasher <span class="token keyword">struct</span> <span class="token punctuation">{</span>
  buf <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span>
<span class="token punctuation">}</span>

<span class="token keyword">func</span> <span class="token punctuation">(</span>h <span class="token operator">*</span>Hasher<span class="token punctuation">)</span> <span class="token function">EncodeBytes</span><span class="token punctuation">(</span>b <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">func</span> <span class="token function">Hash</span><span class="token punctuation">(</span>h <span class="token operator">*</span>Hasher<span class="token punctuation">,</span> obj <span class="token operator">*</span>Obj<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  h<span class="token punctuation">.</span><span class="token function">EncodeBytes</span><span class="token punctuation">(</span>obj<span class="token punctuation">.</span>Data<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Like in the previous example, it is up now to the user to decide how to call the <code>Hash</code> method.</p>
<pre class="language-go"><code class="language-go">obj <span class="token operator">:=</span> <span class="token operator">&amp;</span>Obj<span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token comment">// 1. Declare a specific instance (worse case)</span>
h <span class="token operator">:=</span> <span class="token operator">&amp;</span>Hasher<span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token function">Hash</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> obj<span class="token punctuation">)</span>

<span class="token comment">// 2. Use a pool</span>
<span class="token keyword">var</span> hasherPool <span class="token operator">=</span> sync<span class="token punctuation">.</span>Pool<span class="token punctuation">{</span>
	New<span class="token punctuation">:</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token punctuation">{</span> <span class="token keyword">return</span> <span class="token function">new</span><span class="token punctuation">(</span>Hasher<span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

h <span class="token operator">=</span> hasherPool<span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token operator">*</span>Hasher<span class="token punctuation">)</span>
<span class="token function">Hash</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> obj<span class="token punctuation">)</span>
hasherPool<span class="token punctuation">.</span><span class="token function">Put</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span>
</code></pre>
<p>With the <code>Hasher</code> object, the generated hashing functions become even more succinct (<a href="https://github.com/ferranbt/fastssz/blob/v0.1.3/spectests/structs_encoding.go#L176">here</a>) than the encoding.</p>
<h3>Scotty, we need more power!</h3>
<p>One thing you have to be mindful is that it does not matter how fast the library is, most often than not, that speed comes with a cost in developer experience. Then, it boils down to what the developer is willing to use and what makes sense for its use case.</p>
<p>In <code>fastssz</code> I tried to provide different function flavors with distinct tradeoffs.</p>
<p>In the case of the encoding, two functions are generated, one with and another without the destination buffer:</p>
<pre class="language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>o <span class="token operator">*</span>Object<span class="token punctuation">)</span> <span class="token function">Size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">int</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">func</span> <span class="token punctuation">(</span>o <span class="token operator">*</span>Object<span class="token punctuation">)</span> <span class="token function">MarshalTo</span><span class="token punctuation">(</span>dst <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">func</span> <span class="token punctuation">(</span>o <span class="token operator">*</span>Object<span class="token punctuation">)</span> <span class="token function">Marshal</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span> <span class="token punctuation">{</span>
  buf <span class="token operator">:=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">,</span> o<span class="token punctuation">.</span><span class="token function">Size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> o<span class="token punctuation">.</span><span class="token function">MarshalTo</span><span class="token punctuation">(</span>buf<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre>
<p>An extra function <code>Size</code> is generated and it returns the total size in bytes of the encoded object. Thus, even the less efficient <code>Marshal</code> function only allocates memory once.</p>
<p>For hashing, two functions are generated:</p>
<pre class="language-go"><code class="language-go"><span class="token comment">// fastssz api</span>
<span class="token keyword">func</span> <span class="token function">HashWithDefaultHasher</span><span class="token punctuation">(</span>v HashRoot<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
	hh <span class="token operator">:=</span> DefaultHasherPool<span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
	v<span class="token punctuation">.</span><span class="token function">HashTreeRootWith</span><span class="token punctuation">(</span>hh<span class="token punctuation">)</span>
	root <span class="token operator">:=</span> hh<span class="token punctuation">.</span><span class="token function">HashRoot</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
	DefaultHasherPool<span class="token punctuation">.</span><span class="token function">Put</span><span class="token punctuation">(</span>hh<span class="token punctuation">)</span>
	<span class="token keyword">return</span> root<span class="token punctuation">,</span> err
<span class="token punctuation">}</span>

<span class="token comment">// generated code</span>
<span class="token keyword">func</span> <span class="token punctuation">(</span>o <span class="token operator">*</span>Object<span class="token punctuation">)</span> <span class="token function">HashTreeRootWith</span><span class="token punctuation">(</span>h <span class="token operator">*</span>Hasher<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">func</span> <span class="token punctuation">(</span>o <span class="token operator">*</span>Object<span class="token punctuation">)</span> <span class="token function">HashTreeRoot</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token builtin">byte</span> <span class="token punctuation">{</span>
 <span class="token keyword">return</span> fastssz<span class="token punctuation">.</span><span class="token function">HashWithDefaultHasher</span><span class="token punctuation">(</span>o<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre>
<p>The first function is the low-level one with the allocator while the second one is a more DX-friendly version using the default pool of allocators.</p></main></div></main></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"source":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    a: \"a\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\",\n    h3: \"h3\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"A few years back, the Prysmatic Labs team, developers of the Ethereum Beacon chain \", _jsx(_components.a, {\n        href: \"https://github.com/prysmaticlabs/prysm\",\n        children: \"Prysm\"\n      }), \" \", _jsx(_components.a, {\n        href: \"https://github.com/prysmaticlabs/prysm/issues/4738\",\n        children: \"opened a bounty\"\n      }), \" to replace their implementation (\", _jsx(_components.a, {\n        href: \"https://github.com/prysmaticlabs/go-ssz\",\n        children: \"go-ssz\"\n      }), \") of the SSZ encoding protocol.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Having worked with \", _jsx(_components.a, {\n        href: \"https://github.com/umbracle/fastrlp\",\n        children: \"encoding libraries\"\n      }), \" and \", _jsx(_components.a, {\n        href: \"https://github.com/umbracle/minimal\",\n        children: \"high-performance\"\n      }), \" systems in the blockchain space, I had some ideas I wanted to try out.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"After some successful experiments and a little bit of coding, this was the result:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [\"BenchmarkMarshalGoSSZ\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"-\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"4\"\n        }), \"       \\t  \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"753160\"\n        }), \" ns\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t  \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"115112\"\n        }), \" B\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t    \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"8780\"\n        }), \" allocs\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\nBenchmarkUnMarshalGoSSZ\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"-\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"4\"\n        }), \"     \\t  \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"1395097\"\n        }), \" ns\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t  \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"144608\"\n        }), \" B\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t    \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"8890\"\n        }), \" allocs\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\nBenchmarkMarshal_Fast\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"-\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"8\"\n        }), \"           \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"4088\"\n        }), \" ns\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t    \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"8192\"\n        }), \" B\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t       \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"1\"\n        }), \" allocs\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\nBenchmarkMarshal_SuperFast\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"-\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"8\"\n        }), \"      \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"1354\"\n        }), \" ns\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t       \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"0\"\n        }), \" B\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t       \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"0\"\n        }), \" allocs\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\nBenchmarkUnMarshal_Fast\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"-\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"8\"\n        }), \"         \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"17614\"\n        }), \" ns\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t   \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"11900\"\n        }), \" B\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t     \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"210\"\n        }), \" allocs\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\nBenchmarkHashTreeRoot_Fast\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"-\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"8\"\n        }), \"      \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"45932\"\n        }), \" ns\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t       \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"0\"\n        }), \" B\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\t       \", _jsx(_components.span, {\n          className: \"token number\",\n          children: \"0\"\n        }), \" allocs\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"/\"\n        }), \"op\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For those of you who are not used to Go benchmarks, this is an x500 improvement for message encoding over the original (go-ssz) implementation.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In this blog, I want to give a walkthrough into optimizations behind the library and some of the design decisions. I will focus mostly on encoding and hashing (and a bit less on decoding) since that is where most of the high-performance strategies are located.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"What is SSZ?\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Simple Serialize (SSZ) is a binary data serialization format used in the Ethereum Beacon chain. It replaces the RLP serialization used in the execution clients. Unlike RLP which only specifies the encoding format, SSZ also defines how the objects are Merkleize efficiently.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"SSZ is deterministic and not self-describing, to decode a blob of binary data, the message schema must be known in advance. This differs from Protobuf which encodes in the message itself a description of the format.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Encoding in SSZ is similar in nature to the \", _jsx(_components.a, {\n        href: \"https://docs.soliditylang.org/en/v0.8.19/abi-spec.html\",\n        children: \"ABI format\"\n      }), \" to interact with smart contracts. The result byte stream is divided into two parts: fixed and heap areas. Basic and static values (i.e. integer, bool, fixed size bytes) are appended to the fixed area while dynamic types are written to the heap area recursively following the same rules. An offset is written in the fixed area to the point in the heap where the value starts.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"SSZ objects can also be transformed into a \", _jsx(_components.a, {\n        href: \"https://www.notion.so/Clickhouse-event-tracker-4e8b68a29f62412a9d44d50ba81216c9?pvs=21\",\n        children: \"Merkle-tree\"\n      }), \" representation. The values of the object are recursively split into chunks of 32 bytes and hashed into a Merkle-tree. Additional empty leaves might be included so that the total number of leaves is a power of 2 and a single hash-tree-root is produced.\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Limitations in Golang\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Even though Go does support generic types now, it is still not possible to create a generic data serialization library without the use of the reflect package, a meta-programming tool in Go to determine the shape of the objects at runtime.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A simple encoding library with reflection might look like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [_jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"encode\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"i \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"interface\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  res \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"switch\"\n        }), \" reflect\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"TypeOf\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"i\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Kind\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n    \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"case\"\n        }), \" reflect\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"Int64\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \":\"\n        }), \"\\n      \", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// encode int 64\"\n        }), \"\\n\\t\\t\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"case\"\n        }), \" reflect\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"String\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \":\"\n        }), \"\\n\\t\\t\\t\", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// encode string\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"However, it comes with a cost: it is hard to debug, error-prone, and inefficient.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"An iterative approach to encoding\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Before \", _jsx(_components.code, {\n        children: \"fastssz\"\n      }), \", I built \", _jsx(_components.code, {\n        children: \"[fastrlp](https://github.com/umbracle/fastrlp)\"\n      }), \", a Go library to encode the RLP format of the execution clients. \", _jsx(_components.code, {\n        children: \"fastrlp\"\n      }), \" is based on \", _jsx(_components.code, {\n        children: \"[fastjson](https://github.com/valyala/fastjson)\"\n      }), \" and follows the same structures and optimizations.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.code, {\n        children: \"fastrlp\"\n      }), \" is not an encoding library, but a set of low-level primitives and utilities to encode/decode objects in RLP. The library is small and low-maintenance and if used correctly, it does not allocate any memory.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This is an example of how to use \", _jsx(_components.code, {\n        children: \"fastrlp\"\n      }), \" to encode a simple object with two fields:\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [_jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"type\"\n        }), \" Obj \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"struct\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  A \", _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"uint64\"\n        }), \"\\n  B \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Encode\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  a \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"\u0026\"\n        }), \"fastrlp\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"Arena\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n  v \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" a\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"NewArray\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n  v\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Set\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"a\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"NewUint\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"A\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n  v\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Set\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"a\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"NewBytes\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"B\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"return\"\n        }), \" v\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Marshal\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token boolean\",\n          children: \"nil\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"However, it becomes cumbersome and error-prone to manually write down (and review) the encoding/decoding for each object (\", _jsx(_components.a, {\n        href: \"https://github.com/0xPolygon/polygon-edge/blob/develop/types/rlp_unmarshal.go\",\n        children: \"here\"\n      }), \", \", _jsx(_components.a, {\n        href: \"https://github.com/umbracle/ethgo/blob/main/structs_marshal_rlp.go\",\n        children: \"here\"\n      }), \").\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This is less of a problem for RLP since only a handful of small objects require encoding. But, it is not an option for the Beacon chain which has \", _jsx(_components.a, {\n        href: \"https://github.com/ferranbt/fastssz/blob/main/spectests/structs.go\",\n        children: \"dozens of objects\"\n      }), \" that require SSZ encoding. Thus, I decided to try out code generation to scale the process.\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Code generation is far from perfect\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Most often than not, code generation is used to generate language-specific SDK based on some simple and generic configuration format (i.e. Protobuf, OpenAPI, Kubernetes CRDs, etc…).\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In this case, though Prism does define the Beacon chain objects as \", _jsx(_components.a, {\n        href: \"https://www.notion.so/FastSSZ-SSZ-encoding-on-steroids-e7a2b6eca63b4436936019833a36f8fe?pvs=21\",\n        children: \"Protobuf\"\n      }), \", I decided to work with the Go types instead, not to require any extra bindings to make it work. This decision turned out to have mixed results.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"On one side, it was adopted by other projects (\", _jsx(_components.a, {\n        href: \"https://github.com/Snowfork/snowbridge\",\n        children: \"here\"\n      }), \", \", _jsx(_components.a, {\n        href: \"https://github.com/flashbots/mev-boost-relay\",\n        children: \"here\"\n      }), \") without requiring Protobuf. On the other, when you take as input any arbitrary Go code (and not a constrained schema) you end up facing many Go-specific syntaxes that need support (or at the very least, design discussions), to name a few: import external packages, import with alias names, multiple-target compilation, type alias, etc…\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"A positive aspect of SSZ is that currently is only used for the Ethereum \", _jsx(_components.a, {\n        href: \"https://www.notion.so/FastSSZ-SSZ-encoding-on-steroids-e7a2b6eca63b4436936019833a36f8fe?pvs=21\",\n        children: \"Beacon chain types\"\n      }), \" which are only updated a few times a year. There are not usually new field types that need to be implemented (zero in the last fork).\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Thus, on this aspect, once the code has been generated as it is optimal (more on this in the next section) maintenance is minimal.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Divide and conquer\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Something I found useful while I iterated from \", _jsx(_components.code, {\n        children: \"fastrlp\"\n      }), \" to \", _jsx(_components.code, {\n        children: \"fastssz\"\n      }), \" was to split the system into two layers. On one side the set of high-performance low-level primitives and on the other the code generation (aka \", _jsx(_components.code, {\n        children: \"sszgen\"\n      }), \").\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Some of the benefits are:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"You can optimize and benchmark the encoding outside the generated code.\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"The generated code gets more succinct and easier to read and debug (\", _jsx(_components.a, {\n          href: \"https://github.com/ferranbt/fastssz/blob/main/spectests/structs_encoding.go\",\n          children: \"example\"\n        }), \").\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"There might be simple scenarios where you want to use the primitives without generating code (\", _jsx(_components.a, {\n          href: \"https://github.com/umbracle/go-eth-consensus/blob/main/spec/rewards.go#L21\",\n          children: \"example\"\n        }), \").\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"You can update the library with the primitives without updating the generated code.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Here be dragons! Zero-memory allocation.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Once you remove reflection from the picture, the biggest sinkhole of memory and CPU cycles is going to be memory allocation. Thus, it was my intention to make \", _jsx(_components.code, {\n        children: \"fastssz\"\n      }), \" a zero-allocation library from the get-go.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"First, let's dive in into encoding which is simpler to speed up in SSZ.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Most of the encoding libraries in the literature look like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [_jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"type\"\n        }), \" Obj \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"struct\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  Data \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Encode\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"obj \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  buf \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"make\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n  buf \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"append\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"buf\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"Data\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"...\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"return\"\n        }), \" buf\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In this function, byte allocation for the result happens inside the library. Depending on the object, this allocation might vary a lot in size and might have to be rescaled multiple times. Besides, when executed many times, it creates extra pressure on the gc collector both to allocate the bytes and to track its lifecycle.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"It should be preferable to shift left the allocation and use a destination buffer like this:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [_jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Encode\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"dst \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  dst \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"append\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"dst\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"Data\", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"...\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"return\"\n        }), \" dst\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This is similar to the allocation pattern used in the Zig language.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Then, we remove both the allocation and give more options to the user on how to call this function:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [\"buf \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\nobj \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"\u0026\"\n        }), \"Obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// 1. Encoding gets written to the buffer.\"\n        }), \"\\nbuf \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Encode\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"buf\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// 2. The buffer is reused from the beginning and overwritten with\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// new data.\"\n        }), \"\\nbuf \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Encode\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"buf\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \":\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"0\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// 3. A new buffer is created. Original buffer is garbage collected.\"\n        }), \"\\nbuf \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Encode\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token boolean\",\n          children: \"nil\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Following this pattern, encoding with SSZ is a matter of writing into the destination buffer each field of the object in the correct order (\", _jsx(_components.a, {\n        href: \"https://github.com/ferranbt/fastssz/blob/main/spectests/structs_encoding.go#L128\",\n        children: \"example\"\n      }), \").\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Let’s look at hashing now. In insight, it follows the same principles as encoding except for a couple of differences:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"The result is not a byte stream but a root hash (32 bytes). But, it requires converting the fields into bytes and allocating those intermediate representations somewhere.\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"While the logic in encoding only involves appending bytes into a buffer, for hashing the logic is more complex and requires merkle tree hashing (\", _jsx(_components.a, {\n          href: \"https://github.com/ferranbt/fastssz/blob/v0.1.3/hasher.go#L343\",\n          children: \"example\"\n        }), \").\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The pattern to optimize these operations is similar to encoding, but instead of using \", _jsx(_components.code, {\n        children: \"[]byte\"\n      }), \" as the allocation object, we create a \", _jsx(_components.code, {\n        children: \"Hasher\"\n      }), \" object that encapsulates both the complex hashing logic and the allocation of memory. When doing the hashing of an object, a \", _jsx(_components.code, {\n        children: \"Hasher\"\n      }), \" object has to be passed as well to the function.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [_jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"type\"\n        }), \" Hasher \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"struct\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  buf \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"h \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Hasher\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"EncodeBytes\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"b \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Hash\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"h \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Hasher\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  h\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"EncodeBytes\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"Data\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Like in the previous example, it is up now to the user to decide how to call the \", _jsx(_components.code, {\n        children: \"Hash\"\n      }), \" method.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [\"obj \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"\u0026\"\n        }), \"Obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// 1. Declare a specific instance (worse case)\"\n        }), \"\\nh \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"\u0026\"\n        }), \"Hasher\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Hash\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"h\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// 2. Use a pool\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"var\"\n        }), \" hasherPool \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"=\"\n        }), \" sync\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), \"Pool\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n\\tNew\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \":\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"interface\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"return\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"new\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"Hasher\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\nh \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"=\"\n        }), \" hasherPool\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Get\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Hasher\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Hash\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"h\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" obj\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\nhasherPool\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Put\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"h\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"With the \", _jsx(_components.code, {\n        children: \"Hasher\"\n      }), \" object, the generated hashing functions become even more succinct (\", _jsx(_components.a, {\n        href: \"https://github.com/ferranbt/fastssz/blob/v0.1.3/spectests/structs_encoding.go#L176\",\n        children: \"here\"\n      }), \") than the encoding.\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Scotty, we need more power!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"One thing you have to be mindful is that it does not matter how fast the library is, most often than not, that speed comes with a cost in developer experience. Then, it boils down to what the developer is willing to use and what makes sense for its use case.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In \", _jsx(_components.code, {\n        children: \"fastssz\"\n      }), \" I tried to provide different function flavors with distinct tradeoffs.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In the case of the encoding, two functions are generated, one with and another without the destination buffer:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [_jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Object\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Size\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"int\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Object\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"MarshalTo\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"dst \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Object\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Marshal\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n  buf \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"make\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" o\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Size\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"return\"\n        }), \" o\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"MarshalTo\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"buf\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \":\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"0\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"An extra function \", _jsx(_components.code, {\n        children: \"Size\"\n      }), \" is generated and it returns the total size in bytes of the encoded object. Thus, even the less efficient \", _jsx(_components.code, {\n        children: \"Marshal\"\n      }), \" function only allocates memory once.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"For hashing, two functions are generated:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      className: \"language-go\",\n      children: _jsxs(_components.code, {\n        className: \"language-go\",\n        children: [_jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// fastssz api\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"HashWithDefaultHasher\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"v HashRoot\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"32\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"error\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n\\thh \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" DefaultHasherPool\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Get\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\\tv\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"HashTreeRootWith\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"hh\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\\troot \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \":=\"\n        }), \" hh\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"HashRoot\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\\tDefaultHasherPool\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"Put\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"hh\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\\t\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"return\"\n        }), \" root\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \",\"\n        }), \" err\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token comment\",\n          children: \"// generated code\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Object\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"HashTreeRootWith\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"h \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Hasher\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"func\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o \", _jsx(_components.span, {\n          className: \"token operator\",\n          children: \"*\"\n        }), \"Object\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token function\",\n          children: \"HashTreeRoot\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"[\"\n        }), _jsx(_components.span, {\n          className: \"token number\",\n          children: \"32\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"]\"\n        }), _jsx(_components.span, {\n          className: \"token builtin\",\n          children: \"byte\"\n        }), \" \", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"{\"\n        }), \"\\n \", _jsx(_components.span, {\n          className: \"token keyword\",\n          children: \"return\"\n        }), \" fastssz\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \".\"\n        }), _jsx(_components.span, {\n          className: \"token function\",\n          children: \"HashWithDefaultHasher\"\n        }), _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"(\"\n        }), \"o\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \")\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"token punctuation\",\n          children: \"}\"\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The first function is the low-level one with the allocator while the second one is a more DX-friendly version using the default pool of allocators.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{"title":"FastSSZ: SZZ encoding on esteroids","date":"2023-05-23"}},"frontMatter":{"title":"FastSSZ: SZZ encoding on esteroids","date":"2023-05-23"}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"fastssz-ssz-encoding-on-esteroids"},"buildId":"BvrQde1H6ouQhX5j2uX21","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>